{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:06:35,241 Reading data from training\n",
      "2024-11-14 15:06:35,242 Train: training\\train.txt\n",
      "2024-11-14 15:06:35,243 Dev: training\\dev.txt\n",
      "2024-11-14 15:06:35,243 Test: training\\test_corrected.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\StevenZhou\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\StevenZhou\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\StevenZhou\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:07:24,889 SequenceTagger predicts: Dictionary with 8 tags: <unk>, O, B-PER, I-PER, B-ORG, I-ORG, B-LOC, I-LOC\n",
      "2024-11-14 15:07:24,900 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,901 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): TransformerWordEmbeddings(\n",
      "      (model): RobertaModel(\n",
      "        (embeddings): RobertaEmbeddings(\n",
      "          (word_embeddings): Embedding(50266, 768, padding_idx=1)\n",
      "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "          (token_type_embeddings): Embedding(1, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): RobertaEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0-11): 12 x RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): RobertaPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=868, out_features=868, bias=True)\n",
      "  (rnn): LSTM(868, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2024-11-14 15:07:24,902 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,902 Corpus: 432 train + 44 dev + 142 test sentences\n",
      "2024-11-14 15:07:24,903 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,903 Train:  476 sentences\n",
      "2024-11-14 15:07:24,904         (train_with_dev=True, train_with_test=False)\n",
      "2024-11-14 15:07:24,905 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,905 Training Params:\n",
      "2024-11-14 15:07:24,905  - learning_rate: \"0.1\" \n",
      "2024-11-14 15:07:24,906  - mini_batch_size: \"32\"\n",
      "2024-11-14 15:07:24,906  - max_epochs: \"15\"\n",
      "2024-11-14 15:07:24,907  - shuffle: \"True\"\n",
      "2024-11-14 15:07:24,907 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,907 Plugins:\n",
      "2024-11-14 15:07:24,908  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
      "2024-11-14 15:07:24,909 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,909 Final evaluation on model from best epoch (best-model.pt)\n",
      "2024-11-14 15:07:24,909  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-14 15:07:24,910 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,910 Computation:\n",
      "2024-11-14 15:07:24,911  - compute on device: cpu\n",
      "2024-11-14 15:07:24,911  - embedding storage: cpu\n",
      "2024-11-14 15:07:24,911 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,912 Model training base path: \"resources\\taggers\\ner-english\"\n",
      "2024-11-14 15:07:24,912 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:07:24,913 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\StevenZhou\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flair\\trainers\\trainer.py:499: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and flair.device.type != \"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:07:33,299 epoch 1 - iter 1/15 - loss 1.52928654 - time (sec): 8.38 - samples/sec: 84.56 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:07:42,443 epoch 1 - iter 2/15 - loss 1.08233734 - time (sec): 17.53 - samples/sec: 76.56 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:07:50,357 epoch 1 - iter 3/15 - loss 0.97037187 - time (sec): 25.44 - samples/sec: 80.02 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:07:58,643 epoch 1 - iter 4/15 - loss 0.88852212 - time (sec): 33.73 - samples/sec: 82.90 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:08:05,809 epoch 1 - iter 5/15 - loss 0.80554789 - time (sec): 40.89 - samples/sec: 85.10 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:08:14,302 epoch 1 - iter 6/15 - loss 0.75727072 - time (sec): 49.39 - samples/sec: 83.34 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:08:23,102 epoch 1 - iter 7/15 - loss 0.70130977 - time (sec): 58.19 - samples/sec: 82.97 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:08:34,470 epoch 1 - iter 8/15 - loss 0.69617316 - time (sec): 69.56 - samples/sec: 79.14 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:08:41,321 epoch 1 - iter 9/15 - loss 0.68151871 - time (sec): 76.41 - samples/sec: 80.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:08:47,496 epoch 1 - iter 10/15 - loss 0.67603381 - time (sec): 82.58 - samples/sec: 81.77 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:08:56,118 epoch 1 - iter 11/15 - loss 0.65315274 - time (sec): 91.20 - samples/sec: 81.71 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:09:07,532 epoch 1 - iter 12/15 - loss 0.63131059 - time (sec): 102.62 - samples/sec: 80.37 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:09:16,239 epoch 1 - iter 13/15 - loss 0.62969355 - time (sec): 111.32 - samples/sec: 79.80 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:09:25,012 epoch 1 - iter 14/15 - loss 0.63001562 - time (sec): 120.10 - samples/sec: 79.50 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:09:32,159 epoch 1 - iter 15/15 - loss 0.61611754 - time (sec): 127.25 - samples/sec: 79.40 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:09:32,159 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:09:32,160 EPOCH 1 done: loss 0.6161 - lr: 0.100000\n",
      "2024-11-14 15:09:32,160  - 0 epochs without improvement\n",
      "2024-11-14 15:09:32,161 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:09:41,317 epoch 2 - iter 1/15 - loss 0.63326209 - time (sec): 9.16 - samples/sec: 71.33 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:09:49,319 epoch 2 - iter 2/15 - loss 0.46346892 - time (sec): 17.16 - samples/sec: 76.12 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:09:55,737 epoch 2 - iter 3/15 - loss 0.49662484 - time (sec): 23.57 - samples/sec: 83.82 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:10:07,100 epoch 2 - iter 4/15 - loss 0.47362376 - time (sec): 34.94 - samples/sec: 77.57 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:10:14,576 epoch 2 - iter 5/15 - loss 0.46926338 - time (sec): 42.41 - samples/sec: 81.06 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:10:22,771 epoch 2 - iter 6/15 - loss 0.47719962 - time (sec): 50.61 - samples/sec: 80.91 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:10:31,065 epoch 2 - iter 7/15 - loss 0.48743638 - time (sec): 58.90 - samples/sec: 79.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:10:37,154 epoch 2 - iter 8/15 - loss 0.48066386 - time (sec): 64.99 - samples/sec: 81.86 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:10:45,584 epoch 2 - iter 9/15 - loss 0.46911700 - time (sec): 73.42 - samples/sec: 82.05 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:10:54,324 epoch 2 - iter 10/15 - loss 0.46886698 - time (sec): 82.16 - samples/sec: 81.22 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:11:03,202 epoch 2 - iter 11/15 - loss 0.46797652 - time (sec): 91.04 - samples/sec: 80.96 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:11:09,265 epoch 2 - iter 12/15 - loss 0.46372782 - time (sec): 97.10 - samples/sec: 82.56 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:11:20,604 epoch 2 - iter 13/15 - loss 0.45755195 - time (sec): 108.44 - samples/sec: 80.93 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:11:28,862 epoch 2 - iter 14/15 - loss 0.46796465 - time (sec): 116.70 - samples/sec: 81.48 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:11:35,864 epoch 2 - iter 15/15 - loss 0.46362015 - time (sec): 123.70 - samples/sec: 81.67 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:11:35,865 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:11:35,865 EPOCH 2 done: loss 0.4636 - lr: 0.100000\n",
      "2024-11-14 15:11:35,866  - 0 epochs without improvement\n",
      "2024-11-14 15:11:35,866 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:11:44,793 epoch 3 - iter 1/15 - loss 0.44034280 - time (sec): 8.93 - samples/sec: 84.37 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:11:52,370 epoch 3 - iter 2/15 - loss 0.43495230 - time (sec): 16.50 - samples/sec: 83.92 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:11:59,183 epoch 3 - iter 3/15 - loss 0.43542762 - time (sec): 23.32 - samples/sec: 89.30 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:12:06,618 epoch 3 - iter 4/15 - loss 0.41320951 - time (sec): 30.75 - samples/sec: 87.25 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:12:12,869 epoch 3 - iter 5/15 - loss 0.44873311 - time (sec): 37.00 - samples/sec: 89.78 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:12:21,112 epoch 3 - iter 6/15 - loss 0.43245547 - time (sec): 45.24 - samples/sec: 90.09 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:12:27,143 epoch 3 - iter 7/15 - loss 0.42331792 - time (sec): 51.28 - samples/sec: 89.91 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:12:38,562 epoch 3 - iter 8/15 - loss 0.43043059 - time (sec): 62.69 - samples/sec: 86.85 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:12:50,045 epoch 3 - iter 9/15 - loss 0.44093728 - time (sec): 74.18 - samples/sec: 82.84 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:12:56,428 epoch 3 - iter 10/15 - loss 0.43270643 - time (sec): 80.56 - samples/sec: 83.17 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:13:05,143 epoch 3 - iter 11/15 - loss 0.43768216 - time (sec): 89.28 - samples/sec: 82.60 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:13:14,401 epoch 3 - iter 12/15 - loss 0.42338505 - time (sec): 98.53 - samples/sec: 82.54 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:13:20,433 epoch 3 - iter 13/15 - loss 0.42092333 - time (sec): 104.57 - samples/sec: 83.21 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:13:28,883 epoch 3 - iter 14/15 - loss 0.41102862 - time (sec): 113.02 - samples/sec: 84.48 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:13:35,842 epoch 3 - iter 15/15 - loss 0.40742622 - time (sec): 119.97 - samples/sec: 84.21 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:13:35,843 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:13:35,843 EPOCH 3 done: loss 0.4074 - lr: 0.100000\n",
      "2024-11-14 15:13:35,844  - 0 epochs without improvement\n",
      "2024-11-14 15:13:35,845 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:13:42,942 epoch 4 - iter 1/15 - loss 0.36603612 - time (sec): 7.10 - samples/sec: 78.92 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:13:52,227 epoch 4 - iter 2/15 - loss 0.35044425 - time (sec): 16.38 - samples/sec: 83.21 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:14:00,504 epoch 4 - iter 3/15 - loss 0.35859572 - time (sec): 24.66 - samples/sec: 82.61 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:14:11,921 epoch 4 - iter 4/15 - loss 0.34808525 - time (sec): 36.07 - samples/sec: 76.26 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:14:20,099 epoch 4 - iter 5/15 - loss 0.41675058 - time (sec): 44.25 - samples/sec: 77.30 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:14:27,932 epoch 4 - iter 6/15 - loss 0.38804262 - time (sec): 52.09 - samples/sec: 77.85 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:14:33,990 epoch 4 - iter 7/15 - loss 0.37478452 - time (sec): 58.14 - samples/sec: 80.95 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:14:42,755 epoch 4 - iter 8/15 - loss 0.37332305 - time (sec): 66.91 - samples/sec: 81.15 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:14:48,738 epoch 4 - iter 9/15 - loss 0.36779444 - time (sec): 72.89 - samples/sec: 83.05 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:14:57,031 epoch 4 - iter 10/15 - loss 0.40677094 - time (sec): 81.19 - samples/sec: 82.92 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:15:08,501 epoch 4 - iter 11/15 - loss 0.40272794 - time (sec): 92.65 - samples/sec: 80.44 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:15:15,942 epoch 4 - iter 12/15 - loss 0.40251647 - time (sec): 100.10 - samples/sec: 80.56 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:15:24,157 epoch 4 - iter 13/15 - loss 0.39333148 - time (sec): 108.31 - samples/sec: 80.88 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:15:32,585 epoch 4 - iter 14/15 - loss 0.39563875 - time (sec): 116.74 - samples/sec: 81.51 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:15:40,227 epoch 4 - iter 15/15 - loss 0.38919998 - time (sec): 124.38 - samples/sec: 81.23 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:15:40,227 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:15:40,228 EPOCH 4 done: loss 0.3892 - lr: 0.100000\n",
      "2024-11-14 15:15:40,228  - 0 epochs without improvement\n",
      "2024-11-14 15:15:40,229 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:15:47,699 epoch 5 - iter 1/15 - loss 0.38476839 - time (sec): 7.47 - samples/sec: 94.53 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:15:56,572 epoch 5 - iter 2/15 - loss 0.35930148 - time (sec): 16.34 - samples/sec: 84.94 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:16:05,442 epoch 5 - iter 3/15 - loss 0.35930466 - time (sec): 25.21 - samples/sec: 83.29 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:16:12,759 epoch 5 - iter 4/15 - loss 0.34069856 - time (sec): 32.53 - samples/sec: 83.28 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:16:18,797 epoch 5 - iter 5/15 - loss 0.34388361 - time (sec): 38.57 - samples/sec: 88.60 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:16:27,017 epoch 5 - iter 6/15 - loss 0.32732415 - time (sec): 46.79 - samples/sec: 88.91 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:16:38,504 epoch 5 - iter 7/15 - loss 0.32766878 - time (sec): 58.27 - samples/sec: 85.46 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:16:44,574 epoch 5 - iter 8/15 - loss 0.33704123 - time (sec): 64.34 - samples/sec: 86.32 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:16:50,666 epoch 5 - iter 9/15 - loss 0.32799782 - time (sec): 70.44 - samples/sec: 86.46 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:16:59,332 epoch 5 - iter 10/15 - loss 0.33795134 - time (sec): 79.10 - samples/sec: 87.51 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:17:06,129 epoch 5 - iter 11/15 - loss 0.32977824 - time (sec): 85.90 - samples/sec: 87.27 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:17:14,585 epoch 5 - iter 12/15 - loss 0.33506540 - time (sec): 94.35 - samples/sec: 86.91 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:17:23,796 epoch 5 - iter 13/15 - loss 0.32810799 - time (sec): 103.57 - samples/sec: 86.27 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:17:31,254 epoch 5 - iter 14/15 - loss 0.32845859 - time (sec): 111.02 - samples/sec: 85.71 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:17:38,389 epoch 5 - iter 15/15 - loss 0.32972165 - time (sec): 118.16 - samples/sec: 85.50 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:17:38,389 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:17:38,390 EPOCH 5 done: loss 0.3297 - lr: 0.100000\n",
      "2024-11-14 15:17:38,391  - 0 epochs without improvement\n",
      "2024-11-14 15:17:38,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:17:47,161 epoch 6 - iter 1/15 - loss 0.30526337 - time (sec): 8.77 - samples/sec: 76.30 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:17:54,715 epoch 6 - iter 2/15 - loss 0.32389244 - time (sec): 16.32 - samples/sec: 81.73 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:18:03,884 epoch 6 - iter 3/15 - loss 0.31634458 - time (sec): 25.49 - samples/sec: 79.20 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:18:15,250 epoch 6 - iter 4/15 - loss 0.31652955 - time (sec): 36.86 - samples/sec: 75.64 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:18:23,560 epoch 6 - iter 5/15 - loss 0.32811859 - time (sec): 45.17 - samples/sec: 75.52 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:18:32,202 epoch 6 - iter 6/15 - loss 0.33264859 - time (sec): 53.81 - samples/sec: 76.31 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:18:39,485 epoch 6 - iter 7/15 - loss 0.32400525 - time (sec): 61.09 - samples/sec: 77.41 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:18:48,150 epoch 6 - iter 8/15 - loss 0.32625436 - time (sec): 69.76 - samples/sec: 78.43 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:18:59,568 epoch 6 - iter 9/15 - loss 0.33065648 - time (sec): 81.18 - samples/sec: 76.24 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:19:07,507 epoch 6 - iter 10/15 - loss 0.31766030 - time (sec): 89.11 - samples/sec: 76.52 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:19:13,167 epoch 6 - iter 11/15 - loss 0.30685997 - time (sec): 94.77 - samples/sec: 78.80 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:19:21,830 epoch 6 - iter 12/15 - loss 0.30576841 - time (sec): 103.44 - samples/sec: 78.32 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:19:28,334 epoch 6 - iter 13/15 - loss 0.30118599 - time (sec): 109.94 - samples/sec: 79.71 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:19:36,417 epoch 6 - iter 14/15 - loss 0.30058988 - time (sec): 118.02 - samples/sec: 79.44 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:19:43,661 epoch 6 - iter 15/15 - loss 0.29587354 - time (sec): 125.27 - samples/sec: 80.65 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:19:43,661 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:19:43,662 EPOCH 6 done: loss 0.2959 - lr: 0.100000\n",
      "2024-11-14 15:19:43,663  - 0 epochs without improvement\n",
      "2024-11-14 15:19:43,663 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:19:55,053 epoch 7 - iter 1/15 - loss 0.44106563 - time (sec): 11.39 - samples/sec: 69.11 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:20:04,218 epoch 7 - iter 2/15 - loss 0.34220268 - time (sec): 20.55 - samples/sec: 76.19 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:20:12,460 epoch 7 - iter 3/15 - loss 0.32778583 - time (sec): 28.80 - samples/sec: 79.94 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:20:21,227 epoch 7 - iter 4/15 - loss 0.31265679 - time (sec): 37.56 - samples/sec: 82.00 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:20:27,716 epoch 7 - iter 5/15 - loss 0.29129874 - time (sec): 44.05 - samples/sec: 83.33 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:20:32,998 epoch 7 - iter 6/15 - loss 0.29454401 - time (sec): 49.33 - samples/sec: 86.23 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:20:39,891 epoch 7 - iter 7/15 - loss 0.28578875 - time (sec): 56.23 - samples/sec: 86.74 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:20:51,335 epoch 7 - iter 8/15 - loss 0.28086709 - time (sec): 67.67 - samples/sec: 82.10 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:20:59,995 epoch 7 - iter 9/15 - loss 0.27486359 - time (sec): 76.33 - samples/sec: 81.29 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:21:08,655 epoch 7 - iter 10/15 - loss 0.26901817 - time (sec): 84.99 - samples/sec: 80.37 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:21:16,066 epoch 7 - iter 11/15 - loss 0.27195507 - time (sec): 92.40 - samples/sec: 81.26 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:21:24,297 epoch 7 - iter 12/15 - loss 0.29055415 - time (sec): 100.63 - samples/sec: 80.67 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:21:32,070 epoch 7 - iter 13/15 - loss 0.28120563 - time (sec): 108.41 - samples/sec: 81.40 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:21:39,629 epoch 7 - iter 14/15 - loss 0.27308172 - time (sec): 115.97 - samples/sec: 81.93 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:21:46,984 epoch 7 - iter 15/15 - loss 0.27569923 - time (sec): 123.32 - samples/sec: 81.92 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:21:46,985 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:21:46,985 EPOCH 7 done: loss 0.2757 - lr: 0.100000\n",
      "2024-11-14 15:21:46,986  - 0 epochs without improvement\n",
      "2024-11-14 15:21:46,986 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:21:58,346 epoch 8 - iter 1/15 - loss 0.31374269 - time (sec): 11.36 - samples/sec: 56.69 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:22:06,661 epoch 8 - iter 2/15 - loss 0.31972580 - time (sec): 19.67 - samples/sec: 65.32 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:22:15,349 epoch 8 - iter 3/15 - loss 0.34856246 - time (sec): 28.36 - samples/sec: 68.16 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:22:22,731 epoch 8 - iter 4/15 - loss 0.33034978 - time (sec): 35.74 - samples/sec: 71.73 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:22:28,555 epoch 8 - iter 5/15 - loss 0.30804995 - time (sec): 41.57 - samples/sec: 75.54 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:22:37,651 epoch 8 - iter 6/15 - loss 0.28305028 - time (sec): 50.66 - samples/sec: 75.48 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:22:45,837 epoch 8 - iter 7/15 - loss 0.26958543 - time (sec): 58.85 - samples/sec: 76.26 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:22:54,071 epoch 8 - iter 8/15 - loss 0.26202988 - time (sec): 67.08 - samples/sec: 77.90 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:23:02,423 epoch 8 - iter 9/15 - loss 0.26117800 - time (sec): 75.44 - samples/sec: 77.96 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:23:09,231 epoch 8 - iter 10/15 - loss 0.25204705 - time (sec): 82.24 - samples/sec: 81.54 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:23:20,607 epoch 8 - iter 11/15 - loss 0.24972564 - time (sec): 93.62 - samples/sec: 79.38 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:23:28,139 epoch 8 - iter 12/15 - loss 0.25331144 - time (sec): 101.15 - samples/sec: 80.14 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:23:36,882 epoch 8 - iter 13/15 - loss 0.25436707 - time (sec): 109.90 - samples/sec: 80.18 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:23:44,329 epoch 8 - iter 14/15 - loss 0.25924615 - time (sec): 117.34 - samples/sec: 81.17 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:23:50,002 epoch 8 - iter 15/15 - loss 0.25806754 - time (sec): 123.01 - samples/sec: 82.13 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:23:50,003 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:23:50,003 EPOCH 8 done: loss 0.2581 - lr: 0.100000\n",
      "2024-11-14 15:23:50,004  - 0 epochs without improvement\n",
      "2024-11-14 15:23:50,005 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:23:57,268 epoch 9 - iter 1/15 - loss 0.24119170 - time (sec): 7.26 - samples/sec: 90.87 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:24:08,651 epoch 9 - iter 2/15 - loss 0.33360304 - time (sec): 18.64 - samples/sec: 72.73 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:24:17,340 epoch 9 - iter 3/15 - loss 0.29483853 - time (sec): 27.34 - samples/sec: 75.76 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:24:23,861 epoch 9 - iter 4/15 - loss 0.29550709 - time (sec): 33.86 - samples/sec: 78.33 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:24:32,240 epoch 9 - iter 5/15 - loss 0.29004488 - time (sec): 42.23 - samples/sec: 80.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:24:40,968 epoch 9 - iter 6/15 - loss 0.27163184 - time (sec): 50.96 - samples/sec: 79.23 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:24:52,324 epoch 9 - iter 7/15 - loss 0.27538934 - time (sec): 62.32 - samples/sec: 76.22 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:24:58,242 epoch 9 - iter 8/15 - loss 0.27854404 - time (sec): 68.24 - samples/sec: 78.89 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:25:06,899 epoch 9 - iter 9/15 - loss 0.27115697 - time (sec): 76.89 - samples/sec: 79.58 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:25:14,422 epoch 9 - iter 10/15 - loss 0.26269582 - time (sec): 84.42 - samples/sec: 80.37 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:25:22,680 epoch 9 - iter 11/15 - loss 0.26250167 - time (sec): 92.68 - samples/sec: 80.33 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:25:29,087 epoch 9 - iter 12/15 - loss 0.25307729 - time (sec): 99.08 - samples/sec: 81.63 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:25:37,278 epoch 9 - iter 13/15 - loss 0.25228883 - time (sec): 107.27 - samples/sec: 82.37 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:25:45,153 epoch 9 - iter 14/15 - loss 0.24602229 - time (sec): 115.15 - samples/sec: 82.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:25:51,374 epoch 9 - iter 15/15 - loss 0.24890824 - time (sec): 121.37 - samples/sec: 83.24 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:25:51,374 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:25:51,375 EPOCH 9 done: loss 0.2489 - lr: 0.100000\n",
      "2024-11-14 15:25:51,375  - 0 epochs without improvement\n",
      "2024-11-14 15:25:51,376 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:25:59,448 epoch 10 - iter 1/15 - loss 0.30019602 - time (sec): 8.07 - samples/sec: 76.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:26:05,979 epoch 10 - iter 2/15 - loss 0.23101857 - time (sec): 14.60 - samples/sec: 83.69 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:26:11,712 epoch 10 - iter 3/15 - loss 0.24125117 - time (sec): 20.33 - samples/sec: 87.14 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:26:20,399 epoch 10 - iter 4/15 - loss 0.24417110 - time (sec): 29.02 - samples/sec: 82.52 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:26:29,086 epoch 10 - iter 5/15 - loss 0.24776116 - time (sec): 37.71 - samples/sec: 83.77 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:26:35,064 epoch 10 - iter 6/15 - loss 0.23782469 - time (sec): 43.69 - samples/sec: 87.90 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:26:41,287 epoch 10 - iter 7/15 - loss 0.23452053 - time (sec): 49.91 - samples/sec: 89.04 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:26:49,442 epoch 10 - iter 8/15 - loss 0.23862003 - time (sec): 58.07 - samples/sec: 89.21 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:26:57,330 epoch 10 - iter 9/15 - loss 0.24386857 - time (sec): 65.95 - samples/sec: 89.25 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:27:06,000 epoch 10 - iter 10/15 - loss 0.23827196 - time (sec): 74.62 - samples/sec: 87.33 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:27:14,764 epoch 10 - iter 11/15 - loss 0.23738499 - time (sec): 83.39 - samples/sec: 88.19 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:27:22,527 epoch 10 - iter 12/15 - loss 0.23442118 - time (sec): 91.15 - samples/sec: 87.46 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:27:29,939 epoch 10 - iter 13/15 - loss 0.23211751 - time (sec): 98.56 - samples/sec: 86.57 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:27:41,413 epoch 10 - iter 14/15 - loss 0.22694514 - time (sec): 110.04 - samples/sec: 86.11 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:27:47,854 epoch 10 - iter 15/15 - loss 0.22953600 - time (sec): 116.48 - samples/sec: 86.74 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:27:47,854 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:27:47,855 EPOCH 10 done: loss 0.2295 - lr: 0.100000\n",
      "2024-11-14 15:27:47,856  - 0 epochs without improvement\n",
      "2024-11-14 15:27:47,856 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:27:55,039 epoch 11 - iter 1/15 - loss 0.47770631 - time (sec): 7.18 - samples/sec: 95.94 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:28:03,231 epoch 11 - iter 2/15 - loss 0.33523471 - time (sec): 15.37 - samples/sec: 91.65 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:28:11,658 epoch 11 - iter 3/15 - loss 0.28685176 - time (sec): 23.80 - samples/sec: 87.56 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:28:19,059 epoch 11 - iter 4/15 - loss 0.27222079 - time (sec): 31.20 - samples/sec: 86.31 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:28:27,726 epoch 11 - iter 5/15 - loss 0.28126907 - time (sec): 39.87 - samples/sec: 83.17 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:28:39,070 epoch 11 - iter 6/15 - loss 0.26583082 - time (sec): 51.21 - samples/sec: 79.49 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:28:47,188 epoch 11 - iter 7/15 - loss 0.26447150 - time (sec): 59.33 - samples/sec: 78.44 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:28:55,942 epoch 11 - iter 8/15 - loss 0.24908808 - time (sec): 68.08 - samples/sec: 78.11 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:29:02,040 epoch 11 - iter 9/15 - loss 0.24273830 - time (sec): 74.18 - samples/sec: 79.17 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:29:09,369 epoch 11 - iter 10/15 - loss 0.24201568 - time (sec): 81.51 - samples/sec: 79.85 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:29:18,512 epoch 11 - iter 11/15 - loss 0.23817827 - time (sec): 90.65 - samples/sec: 79.71 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:29:29,857 epoch 11 - iter 12/15 - loss 0.23183729 - time (sec): 102.00 - samples/sec: 78.59 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:29:38,635 epoch 11 - iter 13/15 - loss 0.23589391 - time (sec): 110.78 - samples/sec: 79.24 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:29:46,859 epoch 11 - iter 14/15 - loss 0.22846727 - time (sec): 119.00 - samples/sec: 80.18 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:29:52,461 epoch 11 - iter 15/15 - loss 0.22693677 - time (sec): 124.60 - samples/sec: 81.08 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:29:52,461 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:29:52,462 EPOCH 11 done: loss 0.2269 - lr: 0.100000\n",
      "2024-11-14 15:29:52,462  - 0 epochs without improvement\n",
      "2024-11-14 15:29:52,463 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:30:03,684 epoch 12 - iter 1/15 - loss 0.20786718 - time (sec): 11.22 - samples/sec: 66.22 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:30:12,335 epoch 12 - iter 2/15 - loss 0.19105527 - time (sec): 19.87 - samples/sec: 77.05 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:30:20,488 epoch 12 - iter 3/15 - loss 0.18221573 - time (sec): 28.02 - samples/sec: 78.97 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:30:29,284 epoch 12 - iter 4/15 - loss 0.19916710 - time (sec): 36.82 - samples/sec: 79.47 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:30:37,720 epoch 12 - iter 5/15 - loss 0.18890431 - time (sec): 45.26 - samples/sec: 80.92 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:30:43,948 epoch 12 - iter 6/15 - loss 0.19969040 - time (sec): 51.48 - samples/sec: 83.25 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:30:52,503 epoch 12 - iter 7/15 - loss 0.19925791 - time (sec): 60.04 - samples/sec: 84.21 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:01,657 epoch 12 - iter 8/15 - loss 0.20293562 - time (sec): 69.19 - samples/sec: 83.69 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:07,863 epoch 12 - iter 9/15 - loss 0.20629768 - time (sec): 75.40 - samples/sec: 84.82 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:15,534 epoch 12 - iter 10/15 - loss 0.20706374 - time (sec): 83.07 - samples/sec: 84.84 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:26,839 epoch 12 - iter 11/15 - loss 0.20776995 - time (sec): 94.38 - samples/sec: 80.78 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:35,102 epoch 12 - iter 12/15 - loss 0.20539651 - time (sec): 102.64 - samples/sec: 81.12 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:42,480 epoch 12 - iter 13/15 - loss 0.20517739 - time (sec): 110.02 - samples/sec: 80.72 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:50,629 epoch 12 - iter 14/15 - loss 0.20388884 - time (sec): 118.17 - samples/sec: 80.29 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:58,263 epoch 12 - iter 15/15 - loss 0.20075623 - time (sec): 125.80 - samples/sec: 80.31 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:31:58,264 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:31:58,264 EPOCH 12 done: loss 0.2008 - lr: 0.100000\n",
      "2024-11-14 15:31:58,265  - 0 epochs without improvement\n",
      "2024-11-14 15:31:58,266 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:32:06,118 epoch 13 - iter 1/15 - loss 0.21364738 - time (sec): 7.85 - samples/sec: 79.23 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:32:14,495 epoch 13 - iter 2/15 - loss 0.17336833 - time (sec): 16.23 - samples/sec: 78.69 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:32:22,711 epoch 13 - iter 3/15 - loss 0.17570385 - time (sec): 24.44 - samples/sec: 76.91 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:32:29,852 epoch 13 - iter 4/15 - loss 0.16875627 - time (sec): 31.58 - samples/sec: 80.39 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:32:39,023 epoch 13 - iter 5/15 - loss 0.16548416 - time (sec): 40.76 - samples/sec: 79.20 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:32:47,248 epoch 13 - iter 6/15 - loss 0.17254841 - time (sec): 48.98 - samples/sec: 78.30 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:32:55,907 epoch 13 - iter 7/15 - loss 0.16961773 - time (sec): 57.64 - samples/sec: 78.14 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:33:07,306 epoch 13 - iter 8/15 - loss 0.17394639 - time (sec): 69.04 - samples/sec: 75.83 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:33:14,479 epoch 13 - iter 9/15 - loss 0.17322097 - time (sec): 76.21 - samples/sec: 76.75 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:33:21,883 epoch 13 - iter 10/15 - loss 0.17537751 - time (sec): 83.62 - samples/sec: 77.37 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:33:30,147 epoch 13 - iter 11/15 - loss 0.18103774 - time (sec): 91.88 - samples/sec: 77.09 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:33:38,938 epoch 13 - iter 12/15 - loss 0.18085221 - time (sec): 100.67 - samples/sec: 77.87 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:33:47,742 epoch 13 - iter 13/15 - loss 0.17810355 - time (sec): 109.47 - samples/sec: 78.64 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:33:59,134 epoch 13 - iter 14/15 - loss 0.17988610 - time (sec): 120.87 - samples/sec: 78.64 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:34:06,209 epoch 13 - iter 15/15 - loss 0.18310573 - time (sec): 127.94 - samples/sec: 78.97 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:34:06,210 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:34:06,211 EPOCH 13 done: loss 0.1831 - lr: 0.100000\n",
      "2024-11-14 15:34:06,211  - 0 epochs without improvement\n",
      "2024-11-14 15:34:06,212 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:34:17,638 epoch 14 - iter 1/15 - loss 0.20858252 - time (sec): 11.42 - samples/sec: 69.24 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:34:23,872 epoch 14 - iter 2/15 - loss 0.18850332 - time (sec): 17.66 - samples/sec: 80.08 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:34:32,611 epoch 14 - iter 3/15 - loss 0.18945670 - time (sec): 26.40 - samples/sec: 80.12 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:34:39,841 epoch 14 - iter 4/15 - loss 0.17345861 - time (sec): 33.63 - samples/sec: 85.76 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:34:49,084 epoch 14 - iter 5/15 - loss 0.18353386 - time (sec): 42.87 - samples/sec: 83.30 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:34:57,299 epoch 14 - iter 6/15 - loss 0.18648039 - time (sec): 51.09 - samples/sec: 81.37 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:35:08,681 epoch 14 - iter 7/15 - loss 0.18484450 - time (sec): 62.47 - samples/sec: 80.12 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:35:16,498 epoch 14 - iter 8/15 - loss 0.18655250 - time (sec): 70.28 - samples/sec: 79.95 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:35:25,159 epoch 14 - iter 9/15 - loss 0.18032456 - time (sec): 78.95 - samples/sec: 80.94 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:35:31,886 epoch 14 - iter 10/15 - loss 0.18335087 - time (sec): 85.67 - samples/sec: 81.43 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:35:39,336 epoch 14 - iter 11/15 - loss 0.18421173 - time (sec): 93.12 - samples/sec: 81.78 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:35:47,492 epoch 14 - iter 12/15 - loss 0.18628545 - time (sec): 101.28 - samples/sec: 81.51 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:35:54,217 epoch 14 - iter 13/15 - loss 0.18027371 - time (sec): 108.00 - samples/sec: 81.57 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:36:02,860 epoch 14 - iter 14/15 - loss 0.17983076 - time (sec): 116.65 - samples/sec: 81.70 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:36:10,034 epoch 14 - iter 15/15 - loss 0.17902450 - time (sec): 123.82 - samples/sec: 81.59 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:36:10,035 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:36:10,036 EPOCH 14 done: loss 0.1790 - lr: 0.100000\n",
      "2024-11-14 15:36:10,036  - 0 epochs without improvement\n",
      "2024-11-14 15:36:10,037 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:36:18,701 epoch 15 - iter 1/15 - loss 0.19137005 - time (sec): 8.66 - samples/sec: 70.06 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:36:26,971 epoch 15 - iter 2/15 - loss 0.17980431 - time (sec): 16.93 - samples/sec: 80.85 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:36:33,131 epoch 15 - iter 3/15 - loss 0.17564766 - time (sec): 23.09 - samples/sec: 88.08 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:36:41,252 epoch 15 - iter 4/15 - loss 0.17679909 - time (sec): 31.21 - samples/sec: 86.98 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:36:49,178 epoch 15 - iter 5/15 - loss 0.16788805 - time (sec): 39.14 - samples/sec: 86.02 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:37:00,639 epoch 15 - iter 6/15 - loss 0.17834090 - time (sec): 50.60 - samples/sec: 81.24 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:37:07,792 epoch 15 - iter 7/15 - loss 0.18115141 - time (sec): 57.75 - samples/sec: 81.17 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:37:13,740 epoch 15 - iter 8/15 - loss 0.18299637 - time (sec): 63.70 - samples/sec: 81.22 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:37:25,015 epoch 15 - iter 9/15 - loss 0.18560870 - time (sec): 74.98 - samples/sec: 79.89 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:37:33,657 epoch 15 - iter 10/15 - loss 0.18567197 - time (sec): 83.62 - samples/sec: 80.22 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:37:42,337 epoch 15 - iter 11/15 - loss 0.18907839 - time (sec): 92.30 - samples/sec: 80.23 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:37:48,762 epoch 15 - iter 12/15 - loss 0.18337342 - time (sec): 98.72 - samples/sec: 81.23 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:37:56,498 epoch 15 - iter 13/15 - loss 0.17833061 - time (sec): 106.46 - samples/sec: 82.11 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:38:05,666 epoch 15 - iter 14/15 - loss 0.17575749 - time (sec): 115.63 - samples/sec: 81.93 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:38:13,017 epoch 15 - iter 15/15 - loss 0.17386696 - time (sec): 122.98 - samples/sec: 82.15 - lr: 0.100000 - momentum: 0.000000\n",
      "2024-11-14 15:38:13,018 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:38:13,018 EPOCH 15 done: loss 0.1739 - lr: 0.100000\n",
      "2024-11-14 15:38:13,019  - 0 epochs without improvement\n",
      "2024-11-14 15:38:13,628 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-14 15:38:13,629 Testing using last state of model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:10<00:00,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:38:24,600 \n",
      "Results:\n",
      "- F-score (micro) 0.1788\n",
      "- F-score (macro) 0.1571\n",
      "- Accuracy 0.1046\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ORG     0.2000    0.0303    0.0526        66\n",
      "         PER     0.4800    0.4444    0.4615        27\n",
      "         LOC     1.0000    0.0606    0.1143        33\n",
      "         nk>     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.3019    0.1270    0.1788       126\n",
      "   macro avg     0.4200    0.1338    0.1571       126\n",
      "weighted avg     0.4695    0.1270    0.1564       126\n",
      "\n",
      "2024-11-14 15:38:24,600 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.1787709497206704}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Dictionary\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings, TransformerWordEmbeddings\n",
    "from flair.trainers import ModelTrainer\n",
    "#from datasets import load_dataset\n",
    "\n",
    "# Load the conll2003 dataset with custom code enabled\n",
    "#raw_datasets = load_dataset(\"conll2003\", trust_remote_code=True, cache_dir=\"./cache\")\n",
    "# 1. Load the CoNLL-03 corpus\n",
    "# Specify the folder where your dataset is located and column structure\n",
    "data_folder = 'training'\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# Load the custom dataset\n",
    "corpus = ColumnCorpus(data_folder, columns, train_file='train.txt', test_file='test_corrected.txt', dev_file='dev.txt')\n",
    "\n",
    "# 2. Define the tag type to predict\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. Create the tag dictionary from the corpus\n",
    "# tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "tag_dictionary = Dictionary(add_unk=True)\n",
    "tag_dictionary.add_item('O')\n",
    "tag_dictionary.add_item('B-PER')\n",
    "tag_dictionary.add_item('I-PER')\n",
    "tag_dictionary.add_item('B-ORG')\n",
    "tag_dictionary.add_item('I-ORG')\n",
    "tag_dictionary.add_item('B-LOC')\n",
    "tag_dictionary.add_item('I-LOC')\n",
    "\n",
    "# 4. Initialize embeddings\n",
    "embedding_types = [\n",
    "    WordEmbeddings('glove'), \n",
    "    TransformerWordEmbeddings('roberta-base')\n",
    "]\n",
    "embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. Initialize the sequence tagger\n",
    "tagger = SequenceTagger(\n",
    "    hidden_size=256,\n",
    "    embeddings=embeddings,\n",
    "    tag_dictionary=tag_dictionary,\n",
    "    tag_type=tag_type\n",
    ")\n",
    "\n",
    "# 6. Initialize the trainer\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. Train the model\n",
    "trainer.train(\n",
    "    'resources/taggers/ner-english',\n",
    "    train_with_dev=True,\n",
    "    max_epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# url = \"https://www.foxnews.com/politics/17-retired-military-officials-raise-alarm-bidens-electric-vehicle-push\"\n",
    "# html = urlopen(url).read()\n",
    "with open('fox1.html', 'r', encoding='utf-8') as file:\n",
    "    html = file.read()\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "main_content = soup.find('div', class_='article-body')# called 'article-body' in Fox News\n",
    "paragraphs = main_content.find_all('p')\n",
    "with open(\"txt_output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    # Iterate through paragraphs and write each to the file\n",
    "    for p in paragraphs:\n",
    "        text = p.get_text()\n",
    "        # Split the text into sentences\n",
    "        sentences = text.split('. ')\n",
    "        # Check and write sentences that are not in all caps\n",
    "        for sentence in sentences:\n",
    "            # If the sentence is not in all uppercase, write it to the file\n",
    "            if not sentence.isupper():\n",
    "                file.write(sentence + \".\\n\")\n",
    "\n",
    "#######################################################################################################################################################################################################################################################################################################################\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"resources/taggers/ner-english/final-model.pt\")\n",
    "# make example sentence\n",
    "# sentence = 'One week after challenging the Biden administrations sweeping new emissions standards for cars and light-duty vehicles, a coalition of agricultural, manufacturing and energy production concerns launched lawsuits to block impending rules on trucks and buses. The new standards apply to \"heavy-duty vocational vehicles,\" which also include garbage trucks and bobtails. While the Biden administration and its agencies have strenuously denied the new rules represent a forthcoming \"ban\" on internal combustion engines, plaintiffs were not convinced as they filed petitions in Washington, D.C., federal court this week. The American Petroleum Institute (API) led one suit, which included the American Farm Bureau Federation, Corn Growers Association and Owner-Operator Independent Drivers Association. EPA SUED BY CONSUMER, MANUFACTURING, AGRICULTURAL COALITIONS OVER BIDENS NEW VEHICLE EMISSIONS RULE  The groups named the Environmental Protection Agency (EPA) and Biden-appointed administrator Michael Regan as defendants, while a group headlined by the American Fuel'\n",
    "# Read in a single txt file line by line and save as string\n",
    "file_path = 'txt_output.txt'\n",
    "with open(file_path, encoding = \"utf-8\") as file:\n",
    "    file_content = ''\n",
    "    line = file.readline()\n",
    "     \n",
    "    while line:\n",
    "        file_content += line\n",
    "        line = file.readline()\n",
    "\n",
    "# characters_to_keep = \"-'&\\\".:()\"\n",
    "# translator = str.maketrans('', '', string.punctuation.translate(str.maketrans('', '', characters_to_keep)))\n",
    "# Use translate to remove punctuation\n",
    "# cleaned_sentence = file_content.translate(translator)\n",
    "\n",
    "sent = Sentence(file_content)\n",
    "print(sent.get_spans())\n",
    "# predict NER tags\n",
    "tagger.predict(sent)\n",
    "\n",
    "# print sentence\n",
    "for entity in sent.get_spans('ner'):\n",
    "    print(entity)\n",
    "\n",
    "# print('The following NER tags are found:')\n",
    "\n",
    "# output_file_path = 'ner_results_tested.txt'\n",
    "\n",
    "# with open(output_file_path, 'w', encoding=\"utf-8\") as out_file:\n",
    "    # out_file.write('The following NER tags are found:\\n')\n",
    "    # for entity in sent.get_spans('ner'):\n",
    "        # out_file.write(f'{entity}\\n')  # write each entity to the file\n",
    "\n",
    "# for entity in sent.get_spans('ner'):\n",
    "#    output_file.write(entity)\n",
    "#    print(entity)\n",
    "# output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'ner_results.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding=\"utf-8\") as out_file:\n",
    "    out_file.write('The following NER tags are found:\\n')\n",
    "    for entity in sent.get_spans('ner'):\n",
    "        out_file.write(f'{entity}\\n')  # write each entity to the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
